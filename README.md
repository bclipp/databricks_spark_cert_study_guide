https://academy.databricks.com/exam/databricks-certified-associate-developer
https://spark.apache.org/docs/latest/
https://databricks.com/spark/about

In addition, Sections I, II, and IV of Spark: The Definitive Guide and Chapters 1-7 of Learning Spark should also be helpful in preparation.

**Languages:**
* Python Basics:
https://www.w3schools.com/python/python_intro.asp
* Scala Basics:
 https://www.scala-exercises.org/scala_tutorial/terms_and_types
* SQL: https://www.w3schools.com/sql/sql_intro.asp


**Spark 3 feature highlights:**  
* Adaptive query execution
    * https://databricks.com/session_na20/adaptive-query-execution-speeding-up-spark-sql-at-runtime  
    * https://www.youtube.com/watch?v=jlr8_RpAGuU
* Dynamic partition pruning :
    * https://databricks.com/session_eu19/dynamic-partition-pruning-in-apache-spark
    * https://www.youtube.com/watch?v=-86iMCKeYxI
    * 
* ANSI SQL compliance: 
* Sig python api improvements
* New UI for struct streaming
* 40 X speed up on R UDF
* Accelerator aware scheduler
* SQL Ref Documentation
* Kolas: https://www.youtube.com/watch?v=Ux1A8O6K2Xg&t=10s

**Data:**
* https://www.data.gov/open-gov/
* https://data.richmondgov.com/
* https://data.virginia.gov/
* https://github.com/awesomedata/awesome-public-datasets
* https://www.columnfivemedia.com/100-best-free-data-sources-infographic

**Theory:**
* Spark Architecture:
 https://spark.apache.org/docs/latest/cluster-overview.html
https://www.edureka.co/blog/spark-architecture/
* Job Execution
Quickstart guide: 
https://spark.apache.org/docs/latest/quick-start.html
* Dataframes:
https://spark.apache.org/docs/latest/sql-programming-guide.html
* Cluster mode:
https://spark.apache.org/docs/latest/cluster-overview.html
* Spark session:
https://databricks.com/blog/2016/08/15/how-to-use-sparksession-in-apache-spark-2-0.html
* Scala http://spark.apache.org/docs/latest/api/scala/org/apache/spark/index.html
* SparkSQL http://spark.apache.org/docs/latest/api/sql/index.html
* Adaptive Query Execution: 
https://databricks.com/blog/2020/05/29/adaptive-query-execution-speeding-up-spark-sql-at-runtime.html
https://www.youtube.com/watch?v=jzrEc4r90N8

* Caching data
* UDF (Python, Scala and SQL)
* Shuffling:
https://xuechendi.github.io/2019/04/15/Spark-Shuffle-and-Spill-Explained
https://spark.apache.org/docs/latest/rdd-programming-guide.html#shuffle-operations
http://hydronitrogen.com/apache-spark-shuffles-explained-in-depth.html
https://www.linkedin.com/pulse/spark-sql-3-common-joins-explained-ram-ghadiyaram/
Cluster: https://spark.apache.org/docs/latest/cluster-overview.html
Sub app: https://spark.apache.org/docs/latest/submitting-applications.html
Performance tuning: 
https://spark.apache.org/docs/latest/sql-performance-tuning.html
https://spark.apache.org/docs/latest/tuning.html
Catalyst, logical and physical plan:
https://medium.com/@Shkha_24/catalyst-optimizer-the-power-of-spark-sql-cad8af46097f
Old exam notes:
https://github.com/vivek-bombatkar/Databricks-Apache-Spark-2X-Certified-Developer#a


Videos:
https://www.youtube.com/watch?v=AoVmgzontXo
https://www.youtube.com/watch?v=rl8dIzTpxrI
https://www.youtube.com/watch?v=kkOG_aJ9KjQ
https://www.youtube.com/watch?v=i7l3JQRx7Qw
https://www.youtube.com/watch?v=HZ00AznWvKc
https://www.youtube.com/watch?v=qEKfyoOUKb8&t=4s
https://www.youtube.com/watch?v=f8j5t_xaly4
A Deeper Understanding of Spark Internals - Aaron Davidson (Databricks)
A Tale of Three Apache Spark APIs: RDDs, DataFrames, and Datasets - Jules Damji
Apache Spark Core—Deep Dive—Proper Optimization Daniel Tomes Databricks
Spark + Parquet In Depth: Spark Summit East talk by: Emily Curtin and Robbie Strickland
Spark and Object Stores —What You Need to Know (Steve Loughran)
The Parquet Format and Performance Optimization Opportunities Boudewijn Braams (Databricks)



Useful links:
https://towardsdatascience.com/my-10-recommendations-after-getting-the-databricks-certification-for-apache-spark-53cd3690073




Exercises:
* SQL BASIC (database, tables)
* Scala & SQL Basics
* Load CSV, Avro, parquet, Json
Schema inference
Manually set schema
Add some actions around missing data
Load Data from a JDBC source
Schema inference
Manually set schema
Write data to 
Csv
Json
Avro
Parquet
Json
Jdbc destination
Column:
https://mungingdata.com/apache-spark/column-methods/

Add Columns
Remove columns
Rename columns
Select columns
Concatenating columns
Unique
split
Sort
Drop
Cast
Converting to spark types
 Rows
FIlter/Where
Agg
Groupby
Sum
Avg
Min
Max
Pivot
Rollup
Cube
UDF agg funct
Sampling
Repartitioning and coalesce
Collect
Regular expressions
Dates and timestamp
Nulls
Drop
Fill
Replace
Complex data types
Structs
Arrays
UDF
Scala
Sql
Using scala in python
Joins
Types
spark SQL hive metastore catalog , managed and unmanaged tables, view,
Repartition and Coalesce
Spark app
Spark sql functions
caching
Kolas


